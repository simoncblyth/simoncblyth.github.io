<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>CUDA Context Cleanup &mdash; Env  documentation</title>
    
    <link rel="stylesheet" href="../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../_static/highstock/highstock.js"></script>
    <script type="text/javascript" src="../../_static/highstock/modules/exporting.js"></script>
    <link rel="top" title="Env  documentation" href="../../" />
    <link rel="up" title="cuda" href="../" />
    <link rel="next" title="CUDA Persistent Threads" href="../cuda_persistent_threads/" />
    <link rel="prev" title="CUDA Math" href="../cuda_math/" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex/" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../cuda_persistent_threads/" title="CUDA Persistent Threads"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../cuda_math/" title="CUDA Math"
             accesskey="P">previous</a> |</li>
    <li><a href="/tracs/env/timeline">env</a> &raquo;</li>
    
        <li><a href="../../">Env  documentation</a> &raquo;</li>

          <li><a href="../" accesskey="U">cuda</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search/" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script><h3>Links</h3>
<ul class="this-page-menu">
	<li><a href="/tracs/env"> env </a>  <a href="/tracs/env/timeline"> tl </a> <a href="/repos/env/trunk"> repo </a> <a href="/e"> edocs </a> </li>
	<li><a href="/tracs/heprez"> heprez </a>  <a href="/tracs/heprez/timeline"> tl </a> <a href="/repos/heprez/trunk"> repo</a> <a href="/h">hdocs</a>   </li>
        <li><a href="/e/scm/monitor/" > backup status </a> </li>
</ul>

<h3>Content Skeleton</h3>

<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/">Installing <strong>env</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../base/">Base Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../log/May2012/">LOG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../TODO/">TODO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sysadmin/">Sys Admin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plot/">Plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scm/">SCM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../trac/">Trac</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../root/">ROOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sphinxext/">Sphinx Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../matplotlib/">Matplotlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nose/">nose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../svn/">SVN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../npy/">Numerical Python, numpy et al</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pypy/">PyPy : faster python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mysqlhotcopy/">MySQL hotcopy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mysql/">MySQL Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sqlite/">SQLite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../db/">DB scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../qxml/">QXML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fossil/">Fossil</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../java/">Java Demos</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../">cuda</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../cuda_refs/">CUDA Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_forums/">CUDA Forums</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_toolkit/">CUDA Toolkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../curand/">CUDA Random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../atomic/">CUDA Atomic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_capability/">CUDA Capability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../emulation/">CUDA Emulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cudatoolkit/">CUDA TOOLKIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rcuda/">rCUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_cloud/">CUDA in Cloud</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_osx_driver/">CUDA OSX Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_gdb/">CUDA GDB</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_profiling/">CUDA Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_testing/">CUDA Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_timeouts/">CUDA Error Handling including timeouts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_envvar/">CUDA envvar</a></li>
<li class="toctree-l2"><a class="reference internal" href="../osx_gpu_panic/">OSX GPU Panic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_memory_types/">CUDA Memory Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_math/">CUDA Math</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="">CUDA Context Cleanup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_persistent_threads/">CUDA Persistent Threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_gpu_comparisons/">CUDA GPU Comparisons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../texture/">texture</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../pycuda/">pycuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../geant4/">geant4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../muon_simulation/">muon_simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chroma/">chroma</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../llvm/">llvm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../graphics/">Graphics</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../">cuda</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../cuda_refs/">CUDA Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_forums/">CUDA Forums</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_toolkit/">CUDA Toolkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../curand/">CUDA Random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../atomic/">CUDA Atomic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_capability/">CUDA Capability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../emulation/">CUDA Emulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cudatoolkit/">CUDA TOOLKIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rcuda/">rCUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_cloud/">CUDA in Cloud</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_osx_driver/">CUDA OSX Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_gdb/">CUDA GDB</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_profiling/">CUDA Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_testing/">CUDA Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_timeouts/">CUDA Error Handling including timeouts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_envvar/">CUDA envvar</a></li>
<li class="toctree-l2"><a class="reference internal" href="../osx_gpu_panic/">OSX GPU Panic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_memory_types/">CUDA Memory Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_math/">CUDA Math</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="">CUDA Context Cleanup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_persistent_threads/">CUDA Persistent Threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_gpu_comparisons/">CUDA GPU Comparisons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../texture/">texture</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../opencl/">opencl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/">Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cloud/">Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package_management/">Package Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ui/">ui</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../debugging/">debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mercurial/">mercurial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../javascript/">javascript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nuwa/">nuwa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ccgpu/">ccgpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pygame/">pygame</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../zeromq/">zeromq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../doc/">doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../osx/">osx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hg/">hg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../simoncblyth.bitbucket.org/">simoncblyth.bitbucket.org</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../numpy/">numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/">Muon Simulation Presentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optix/">optix</a></li>
</ul>

  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../../_sources/cuda/cuda_context_cleanup.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
  <h4>Previous topic</h4>
  <p class="topless"><a href="../cuda_math/"
                        title="previous chapter">CUDA Math</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../cuda_persistent_threads/"
                        title="next chapter">CUDA Persistent Threads</a></p>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="cuda-context-cleanup">
<h1>CUDA Context Cleanup<a class="headerlink" href="#cuda-context-cleanup" title="Permalink to this headline">¶</a></h1>
<p>Observe that GPU memory usage is high and stays high for minutes
even when no applications are actively using the GPU.</p>
<p>Is this due to bad actors not cleaning up their CUDA Contexts ?</p>
<ul class="simple">
<li>does host thread death automatically cleanup any CUDA contexts that were openend ?</li>
</ul>
<div class="section" id="running-with-osx-in-normal-gui-mode">
<h2>Running with OSX in normal GUI mode<a class="headerlink" href="#running-with-osx-in-normal-gui-mode" title="Permalink to this headline">¶</a></h2>
<p>Immediately after restart with Finder, Safari and Terminal:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Dec  1 13:25:26 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              447.8M
memory free              1.7G
delta:~ blyth$</pre>
</div>
<p>After a ~20min in Safari, Terminal, Sys Prefs a whole gig of GPU memory is gone:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Dec  1 13:42:33 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              1.4G
memory free              738.7M
delta:~ blyth$</pre>
</div>
<p>After sleeping during lunch, 1G of VRAM frees up:</p>
<div class="highlight-python"><pre>delta:env blyth$ cuda_info.sh
timestamp                Mon Dec  1 14:55:09 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              440.8M
memory free              1.7G
delta:env blyth$</pre>
</div>
</div>
<div class="section" id="pragmatic-solution">
<h2>Pragmatic Solution<a class="headerlink" href="#pragmatic-solution" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>run in &#8220;&gt;console&#8221; mode when you need maximum GPU memory</li>
<li>for GUI usage, restart the machine often to ensure will have enough GPU memory<ul>
<li>TODO: add a GPU memory configurable minimum to g4daeview.py, it will try to
run with mapped/pinned host memory but the performance is factor 3-4 lower that
when sufficient memory to go GPU resident</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="osx-vram">
<h2>OSX VRAM<a class="headerlink" href="#osx-vram" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://forums.adobe.com/thread/1326404">https://forums.adobe.com/thread/1326404</a><ul>
<li>some Adobe raycaster, running into VRAM pressure</li>
</ul>
</li>
<li><a class="reference external" href="http://www.anandtech.com/show/2804">http://www.anandtech.com/show/2804</a></li>
<li><a class="reference external" href="http://arstechnica.com/apple/2005/04/macosx-10-4/13/">http://arstechnica.com/apple/2005/04/macosx-10-4/13/</a><ul>
<li>abouts OSX VRAM usage, number of open windows matters</li>
</ul>
</li>
<li>retina screen support is presumably eating lots of VRAM</li>
</ul>
</div>
<div class="section" id="running-without-gui-using-console-login">
<h2>Running without GUI using &#8220;&gt;console&#8221; login<a class="headerlink" href="#running-without-gui-using-console-login" title="Permalink to this headline">¶</a></h2>
<p>GPU memory is almost entirely free:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Nov 24 12:57:17 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              96.0M
memory free              2.1G
delta:~ blyth$</pre>
</div>
<p>While running g4daechroma.sh:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Nov 24 13:01:46 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              111.2M
memory free              2.0G</pre>
</div>
<p>Huh memory usage seems variable, sometimes get 220M used.</p>
<p>After one mocknuwa run:</p>
<div class="highlight-python"><pre>elta:~ blyth$ cuda_info.sh
timestamp                Mon Nov 24 13:04:28 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              277.2M
memory free              1.9G
delta:~ blyth$</pre>
</div>
<p>After 2nd mocknuwa, not increasing:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Nov 24 13:06:13 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              277.2M
memory free              1.9G
delta:~ blyth$</pre>
</div>
<p>ctrl-c interrupt g4daechroma.py cleans up ok:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Nov 24 13:07:50 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              96.0M
memory free              2.1G
delta:~ blyth$</pre>
</div>
<p>Repeating:</p>
<div class="highlight-python"><pre>delta:~ blyth$ cuda_info.sh
timestamp                Mon Nov 24 13:09:06 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              111.2M
memory free              2.0G</pre>
</div>
<p>Mem reporting from inside the process doesnt match the above:</p>
<div class="highlight-python"><pre>chroma_env)delta:MockNuWa blyth$ python mocknuwa.py
             a_min_free_gpu_mem :     300.00M  300000000
             b_node_array_usage :      54.91M  54909600
                b_node_itemsize :      16.00M  16
                  b_split_index :       3.43M  3431850
                      b_n_extra :       1.00M  1
                      b_n_nodes :       3.43M  3431850
                    b_splitting :       0.00M  0
              c_triangle_nbytes :      28.83M  28829184
                 c_triangle_gpu :       1.00M  1
              d_vertices_nbytes :      14.60M  14597424
                 d_triangle_gpu :       1.00M  1
                     a_gpu_used :      99.57M  99573760
                     b_gpu_used :     129.72M  129720320
                     c_gpu_used :     184.64M  184639488
                     d_gpu_used :     213.48M  213475328
                     e_gpu_used :     228.16M  228155392
(chroma_env)delta:MockNuWa blyth$</pre>
</div>
<p>Huh GPUGeometry init only happening when the first evt arrives:</p>
<div class="highlight-python"><pre>2014-11-24 13:22:58,720 INFO    env.geant4.geometry.collada.g4daeview.daedirectpropagator:53  DAEDirectPropagator ctrl {u'reset_rng_states': 1, u'nthreads_per_block': 64, u'seed': 0, u'max_blocks': 1024, u'max_steps': 30, u'COLUMNS': u'max_blocks:i,max_steps:i,nthreads_per_block:i,reset_rng_states:i,seed:i'}
2014-11-24 13:22:58,720 WARNING env.geant4.geometry.collada.g4daeview.daedirectpropagator:63  reset_rng_states
2014-11-24 13:22:58,720 INFO    env.geant4.geometry.collada.g4daeview.daechromacontext:182 _set_rng_states
2014-11-24 13:22:58,851 INFO    chroma.gpu.geometry :19  GPUGeometry.__init__ min_free_gpu_mem 300000000.0
2014-11-24 13:22:59,073 INFO    chroma.gpu.geometry :206 Optimization: Sufficient memory to move triangles onto GPU
2014-11-24 13:22:59,085 INFO    chroma.gpu.geometry :220 Optimization: Sufficient memory to move vertices onto GPU
2014-11-24 13:22:59,085 INFO    chroma.gpu.geometry :248 device usage:
----------
nodes             3.4M  54.9M
total                   54.9M
----------
device total             2.1G
device used            228.2M
device free              1.9G

2014-11-24 13:22:59,089 INFO    env.geant4.geometry.collada.g4daeview.daechromacontext:177 _get_rng_states
2014-11-24 13:22:59,090 INFO    env.geant4.geometry.collada.g4daeview.daechromacontext:132 setup_rng_states using seed 0
2014-11-24 13:22:59,512 INFO    chroma.gpu.photon_hit:204 nwork 4165 step 0 max_steps 30 nsteps 30
2014-11-24 13:23:00,157 INFO    chroma.gpu.photon_hit:242 step 0 propagate_hit_kernel times  [0.6453909912109375]
2014-11-24 13:23:00,319 INFO    env.geant4.geometry.collada.g4daeview.daedirectpropagator:86  daedirectpropagator:propagate returning photons_end.as_npl()</pre>
</div>
<p>Timings are not stable, even when running in console mode with no memory or other GPU user
contention.</p>
</div>
<div class="section" id="stuck-python-process">
<h2>Stuck Python Process<a class="headerlink" href="#stuck-python-process" title="Permalink to this headline">¶</a></h2>
<p>Killing an old stuck process succeeds to free some ~200M of GPU memory,
but still how is 1.7 G being used.
When running with visible apps only Finder and Terminal.</p>
<div class="highlight-python"><pre>(chroma_env)delta:MockNuWa blyth$ cuda_info.py
timestamp                Mon Nov 24 12:40:09 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              1.9G
memory free              232.1M
(chroma_env)delta:MockNuWa blyth$ ps aux | grep python
blyth           69938   1.2  0.2 35266100  31340 s000  S+    3Nov14 126:41.78 python /Users/blyth/env/bin/daedirectpropagator.py mock001
blyth            2313   0.0  0.0  2423368    284 s007  R+   12:40PM   0:00.00 grep python
(chroma_env)delta:MockNuWa blyth$ kill -9 69938
(chroma_env)delta:MockNuWa blyth$ ps aux | grep python
blyth            2315   0.0  0.0  2423368    240 s007  R+   12:40PM   0:00.00 grep python
(chroma_env)delta:MockNuWa blyth$ cuda_info.py
timestamp                Mon Nov 24 12:40:47 2014
tag                      default
name                     GeForce GT 750M
compute capability       (3, 0)
memory total             2.1G
memory used              1.7G
memory free              400.0M</pre>
</div>
</div>
<div class="section" id="search">
<h2>Search<a class="headerlink" href="#search" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="http://www.google.com/search?q=CUDA Context Cleanup">google:CUDA Context Cleanup</a></li>
</ul>
<p><a class="reference external" href="https://devblogs.nvidia.com/parallelforall/pro-tip-clean-up-after-yourself-ensure-correct-profiling/">https://devblogs.nvidia.com/parallelforall/pro-tip-clean-up-after-yourself-ensure-correct-profiling/</a></p>
<blockquote>
<div>If your application uses the CUDA Runtime API, call cudaDeviceReset() just
before exiting, or when the application finishes making CUDA calls and using
device data. If your application uses the CUDA Driver API, call
cuProfilerStop() on each context to flush the profiling buffers before
destroying the context with cuCtxDestroy().</div></blockquote>
<div class="sidebar">
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex/" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../cuda_persistent_threads/" title="CUDA Persistent Threads"
             >next</a> |</li>
        <li class="right" >
          <a href="../cuda_math/" title="CUDA Math"
             >previous</a> |</li>
    <li><a href="/tracs/env/timeline">env</a> &raquo;</li>
    
        <li><a href="../../">Env  documentation</a> &raquo;</li>

          <li><a href="../" >cuda</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2012, Simon C Blyth.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.
    </div>
  </body>
</html>